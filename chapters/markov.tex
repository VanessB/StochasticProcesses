\section{Марковские процессы} \label{section:markov}

В этом разделе мы приступаем к изучению еще одного важного класса процессов,
который является обобщением динамических систем,
то есть систем, будущие состояния которых определяются лишь текущим состоянием.
Это \defemph{марковские процессы}, и им будет посвящена вся оставшаяся часть учебного пособия.

\begin{definition}
    \label{definition:markov:markov_process}
    Случайный процесс $ X $ называется \defemph{марковским} в случае, когда
    \begin{multline*}
        \forall B \in \setfamily, \; \forall n \in \naturals, \; \forall \{ t_k \}_{k=1}^{n+1} \subseteq T, \; \forall \{ x_k \}_{k=1}^n \subseteq \reals \\
        \proba \left\{ X_{t_{n+1}} \in B \Mid X_{t_n} = x_n, X_{t_{n-1}} = x_{n-1}, \ldots, X_{t_1} = x_1 \right\} =
        \proba \left\{ X_{t_{n+1}} \in B \Mid X_{t_n} = x_n \right\}
    \end{multline*}
\end{definition}

Обратите внимание, что в определении выше важно,
что в условии стоят события вида $ X_{t_k} = x_k $,
а не, например, $ X_{t_k} \in B_k $ для $ B_k \in \setfamily $,
так как иначе определение было бы неэквивалентным и неверным.
Под марковостью процесса следует понимать именно то, что написано в определении.

Неформально говоря, случайный процесс называется марковским,
если вероятностные характеристики его <<будущего>> (в момент $ t_{n+1} $)
зависят лишь от значения процесса, которое он принял в <<настоящем>> (в момент $ t_n $),
и не зависят от значений, которые процесс принимал в <<прошлом>> (в моменты $ t_{n-1}, \ldots, t_1 $).
Этим свойством обладают обычные, неслучайные детерминированные процессы,
когда текущее состояние системы однозначно определяет будущие состояния.
В марковских же процессах однозначно определены вероятностные характеристики процесса в будущем,
если известно состояние системы в настоящем.

Область применения марковских процессов необъятна,
они широко используются для описания явлений в физике
(особенно в термодинамике и процессах диффузии), химии, экономике,
финансовой математике, теории обработки сигналов, навигации, теории информации,
теории распознавания речи, в IT-технологиях,
являются базовой моделью в теории машинного обучения с подкреплением
(см. \emph{марковский процесс принятия решений}).

Заметим, что винеровский, пуассоновский, а также процессы случайных блужданий являются марковскими:

\begin{statement}
    \label{statement:markov:independent_deltas_imply_markov}
    Всякий процесс с независимыми приращениями является марковским процессом.
\end{statement}

Если процесс является марковским, то отсюда, вообще говоря, не следует,
что он является процессом с независимыми приращениями.

\begin{example}
    \label{example:markov:markov_but_not_independent_deltas}
    Пусть $ \eta \sim U_{[-1;1]} $, $ T = [0;+\infty) $.
    Процесс $ X_t = \eta \cdot t $ является марковским
    (т.к. $ X_{t_{n+1}} = X_{t_n} \cdot \frac{t_{n+1}}{t_n} $, если $ t_n > 0 $).
    но не является процессом с независимыми приращениями.
    Например, $ \proba \{ X_2 - X_1 \in [0;1] \mid X_1 = -1 \} = 0 $, хотя $ \proba \{ X_2 - X_1 \in [0;1] \} = 1/2 $.
\end{example}

\begin{table}[ht!]
    \center
    \begin{tabular}{c||c|c}
                                          & $ T $ дискретно & $ T $ непрерывно \\
        \hline
        \hline
        $ S $ дискретно                   & \makecell[c]{Дискретная цепь Маркова \\ (напр., подбрасывание монетки)} & \makecell[c]{Непрерывная цепь Маркова \\ (напр., $ K $)} \\
        \hline
        \multirow{3}{*}{$ S $ непрерывно} & \multicolumn{2}{c}{Непрерывный процесс Маркова} \\
                                          & \makecell[c]{(напр., $ X_t = \sum_{k < t} \xi_k $, \\ $ \xi_k \sim \normal(0,1) $~--- \iid)} & (напр., $ W $) \\
    \end{tabular}
    \label{table:markov:classification}
    \caption{Классификация марковских процессов по множествам $ S $ и $ T $.}
\end{table}

Марковские процессы классифицируются по множеству значений, которые они могут принимать
(то есть по \defemph{множеству состояний}, обозначим его $ S $), и множеству времён $ T $.
Классификация и релевантные примеры указаны в таблице \ref{table:markov:classification}.

\FloatBarrier




\subsection{Дискретные марковские цепи} \label{subsection:markov:markov_chains}

Начнём изучение марковских процессов с наиболее простых представителей данного класса~--- \defemph{дискретных марковских цепей}.
Поскольку $ S $ дискретно (т.е. не более, чем счётно),
можно пронумеровать все состояния.
Без ограничения общности будем отождествлять состояние $ s_i \in S $ и его номер $ i $.
Аналогично отождествим $ t_k \in T $ и $ k $.

\begin{definition}
    \label{definition:markov:transition_matrix}
    Пусть $ X $~--- дискретная марковская цепь.
    Числа $ p_{ij}(k, n) = \proba \{X_n = j \mid X_k = i \} $ называются \defemph{переходными вероятностями}
    (из состояния $ i $ в состояние $ j $ с шага $ k $ на шаг $ n $)
    Матрица $ P(k,n) = (p_{ij}(k,n))_{i,j \in S} $ называется \defemph{матрицей переходных вероятностей}.
\end{definition}

\begin{remark}
    \label{remark:markov:transition_matrix_basic_properties}
    Все элементы матрицы $ P(k,n) $ лежат на отрезке $ [0;1] $,
    сумма всех элементов в каждой строке матрицы $ P(k,n) $ равна единице.
\end{remark}

\begin{statement}{Уравнения Колмогорова-Чеппмена}
    \label{statement:markov:Kolmogorov-Chapman_equations}
    Для всех $ k < m < n $ верно $ P(k,n) = P(k,m) \cdot P(m,n) $.
\end{statement}

\begin{proof}
    Это эквивалентно $ p_{ij}(k,n) = \sum_{\alpha \in S} p_{i \alpha}(k,m) p_{\alpha j}(m,n) $,
    что является формулой полной вероятности для $ p_{ij}(k,n) $ с учётом марковости процесса.
\end{proof}

\begin{definition}
    \label{definition:markov:distribution_vector}
    Распределение сечения дискретной марковской цепи на $ k $-ом шаге $ X_k $ можно задавать
    \defemph{вектором вероятностей состояний на $ k $-ом шаге} $ \pi(k) = (\proba \{ X_k = i \})_{i \in S} $.
    Вектор $ \pi(0) $ называется \defemph{начальным распределением} $ X $.
\end{definition}

\begin{statement}
    \label{statement:markov:distribution_dynamics}
    Для любых $ k < n $ выполнено $ \pi(n) = P^T(k,n) \pi(k) $.
\end{statement}

Из всех приведённых определений и утверждений следует,
что динамика дискретной марковской цепи полностью описывается в терминах $ P $ и $ \pi $.



\subsubsection{Однородные дискретные марковские цепи} \label{subsubsection:markov:homogenous}

Часто переходные вероятности не зависят от того, какие именно моменты времени рассматриваются,
а зависят только от промежутка между этими моментами.
В таком случае марковская цепь называется \defemph{однородной}.

\begin{definition}
    \label{definition:markov:homogenous_markov_chain}
    Дискретная марковская цепь называется однородной в случае,
    когда $ P(k,n) $ зависит только от $ n - k $.
\end{definition}

Далее <<однородную дискретную марковскую цепь>> будем сокращать до <<ОДМЦ>>.

\begin{corollary}
    \label{corollary:markov:transition_matrix_power}
    В случае ОДМЦ верно $ P(k,n) = P^{n - k} $, $ \pi(n) = (P^n)^T \pi(0) $, где $ P \defeq P(0,1) $~---
    матрица вероятностей перехода за один шаг.
\end{corollary}

\begin{proof}
    Следует из утверждений \ref{statement:markov:Kolmogorov-Chapman_equations}, \ref{statement:markov:distribution_dynamics} и определения \ref{definition:markov:homogenous_markov_chain}.
\end{proof}

\begin{exercise}
    \label{exercise:markov:dice}
    Пусть $ \eta_n $~--- число выпавших очков при $ n $-ом независимом подбрасывании кубика,
    а $ \xi_n = \max \{\eta_1, \ldots, \eta_n \} $.
    Выписать матрицу переходных вероятностей этой марковской цепи.
\end{exercise}

\begin{solution}
    Если уже набрано $ k $ очков, то при очередном броске счёт не может уменьшиться.
    С вероятностью $ k/6 $ он останется тем же (выпало $ \leqslant k $),
    с вероятностями $ 1/6 $~--- увеличится на $ 1, \ldots, 6-k $.
    \[
        P =
        \begin{bmatrix}
            1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 \\
            0   & 2/6 & 1/6 & 1/6 & 1/6 & 1/6 \\
            0   & 0   & 3/6 & 1/6 & 1/6 & 1/6 \\
            0   & 0   & 0   & 4/6 & 1/6 & 1/6 \\
            0   & 0   & 0   & 0   & 5/6 & 1/6 \\
            0   & 0   & 0   & 0   & 0   & 6/6 \\
        \end{bmatrix}
    \]
\end{solution}

\begin{exercise}
    \label{exercise:markov:two_states_hdmc}
    Дана однородная марковская цепь с множеством состояний~--- $ S = \{0,1\} $.
    Матрица переходов~--- $ P = \begin{bmatrix} 1 - p & p \\ q & 1 - q \end{bmatrix} $,
    где $ p,q \in (0;1) $.
    Найдите $ \proba \{ X_n = 0 \mid X_0 = 0 \} $.
\end{exercise}

\begin{solution}
    Собственные значения матрицы вероятностей переходов~--- $ \lambda_1 = 1 $, $ \lambda_2 = 1 - p - q \neq 1 $.
    Пользуясь общей формулой возведения матрицы $ 2 \times 2 $ в степень,\footnote{\url{https://people.math.carleton.ca/~williams/papers/pdf/175.pdf}}
    \[
        P(n) = P^n = \frac{\lambda_1^n}{\lambda_1 - \lambda_2}(P - \lambda_2 I) - \frac{\lambda_2^n}{\lambda_1 - \lambda_2}(P - \lambda_1 I) =
        \frac{1}{p + q} \left( (1 - \lambda_2^n) P + (\lambda_2^n - \lambda_2) I \right)
    \]
    Левый верхний элемент матрицы равен
    \[
        \frac{1}{p + q} \left( (1 - \lambda_2^n)(1 - p) + (\lambda_2^n - \lambda_2) \right) = \frac{1}{p + q}(q + p (1 - p - q)^n)
    \]
\end{solution}

Поскольку в случае ОДМЦ имеем $ \pi(n) = (P^n)^T \pi(0) $, возникает вопрос,
будет ли любое начальное распределение стремиться к некоторому <<стационарному>>
в связи с возникшей матричной степенью.
Подойдём к ответу издалека, изучив спектральные свойства матрицы переходных вероятностей.

\begin{definition}
    \label{definition:markov:stationary_distribution}
    \uline{Распределение} $ \pi^* $ называется \defemph{стационарным для матрицы переходных вероятностей $ P $} в случае $ \pi^* = P^T \pi^* $.
\end{definition}

Стационарное распределение~--- это левый вектор матрицы $ P^T $,
отвечающий собственному значению $ \lambda = 1 $,
причём обязательно являющийся распределением вероятностей
(произвольный собственный вектор в общем случае не является стационарным распределением).

Матрица $ P $ с неотрицательными элементами такими,
что сумма элементов любой строки равна $ 1 $, называется стохастической.
Очевидно, что у стохастической матрицы $ \lambda = 1 $~--- собственное число,
поскольку вектор $ (1, 1, \ldots, 1)^T $~--- собственный.
А стационарное распределение~--- левый собственный вектор,
то есть правый собственный вектор сопряжённой матрицы.
Но из наличия точки $ 1 $ в спектре этой матрицы, конечно, ещё не следует,
что существует собственный вектор~--- распределение.

\begin{exercise}
    \label{exercise:markov:stationary_dice}
    Для марковской цепи из задачи \ref{exercise:markov:dice} найти стационарное распределение.
\end{exercise}

\begin{solution}
    Матрица треугольная, поэтому все собственные значения находятся на диагонали.
    Так как на диагонали только одно число <<$ 1 $>>,
    геометрическая кратность данного собственного числа равна единице.
    Отсюда следует, что существует только одно стационарное распределение.
    Нетрудно проверить, что оно~--- $ \pi^* = (0,0,0,0,0,1)^T $.
\end{solution}

\begin{definition}
    \label{definition:markov:limit_distribution}
    \defemph{Предельное распределение} стохастической матрицы $ P $~---
    распределение $ \pi = \{\pi_j, j \in S\} $ такое,
    что во всякой ОДМЦ с матрицей переходных вероятностей $ P $
    и произвольным начальным распределением выполнено $ \pi = \lim_{n \to \infty} \pi(n) $,
    то есть $ \proba \{X_n = j\} \limarrow{n \rightarrow \infty} \pi_j $.
\end{definition}

\begin{statement}
    \label{statement:markov:limit_implies_stationary}
    Если предельное распределение существует,
    то оно единственно и стационарно.
\end{statement}

Соотношения между стационарными и предельными распределениями иллюстрируют следующие примеры:

\begin{example}
    \label{example:markov:stationary_but_not_limit}
    В цепи с $ P = I $ любое распределение стационарное,
    но предельного распределения нет.
\end{example}

\begin{example}
    \label{example:markov:single_stationary_but_not_limit}
    В цепи с $ |S| = 2 $, $ P = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} $ только распределение
    $ \pi^* = (1/2, 1/2)^T $ является стационарным, предельного распределения нет.
\end{example}

\begin{example}
    \label{example:markov:no_stationary}
    Рассмотрим цепь с $ S = \naturals $, $ p_{ij} = \delta_{j,i+1} $
    (то есть из каждого состояния с вероятностью $ 1 $ осуществляется переход в следующее за ним).
    В таком случае матрица $ P $ бесконечна и содержит нули везде,
    кроме верхней побочной диагонали (там стоят единицы).
    Уравнение $ \pi = P^T \pi $ имеет единственное решение $ \pi = 0 $.
    Это даже не распределение.
\end{example}

\begin{statement}
    \label{statement:markov:has_limit}
    Пусть $ P $~--- матрица вероятностей переходов некоторой ОДМЦ.
    Пусть $ \exists n_0 \in \naturals $ такое, что все элементы $ P^{n_0} $ положительны.
    Тогда в такой марковской цепи существует предельное распределение.
\end{statement}

\begin{definition}
    \label{definition:markov:ergodic_chain}
    Марковская цепь называется \defemph{эргодической},
    если у неё существует предельное распределение с \uline{положительными вероятностями всех состояний}.
\end{definition}

\begin{example}
    \label{example:markov:has_limit_but_not_ergodic}
    Приведём два примера: эргодической цепи и неэргодической с предельным распределением.
    \begin{enumerate}
        \item
            В цепи с $ |S| = 2 $ и $ P = \begin{bmatrix} 0 & 1 \\ 0 & 1 \end{bmatrix} $
            есть предельное распределение $ \pi = (0, 1)^T $, но цепь не эргодична.
        \item
            В цепи с $ |S| = 2 $ и $ P = \begin{bmatrix} p & 1 - p \\ 1 & 0 \end{bmatrix} $
            есть предельное эргодическое распределение, поскольку
            $ P^n \limarrow{n \to \infty} \frac{1}{2 - p} \begin{bmatrix} 1 & 1 - p \\ 1 & 1 - p \end{bmatrix} $
            (видно, что умножение $ P^T $ на любой вектор-распределение даёт $ \left( \frac{1}{2 - p}, \frac{1 - p}{2 - p} \right)^T $).
    \end{enumerate}
\end{example}

Позже мы дадим критерий эргодичности марковской цепи.
