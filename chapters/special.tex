\section{Важные примеры случайных процессов} \label{section:special}

В этом разделе речь пойдёт о нескольких процессах особого вида,
наиболее часто встречающихся при исследовании реальных явлений.
Зачастую такие процессы именные.
На их примере мы продолжим практиковаться в решении задач,
а также введём несколько новых теоретических понятий.


\subsection{Пуассоновский процесс} \label{subsection:special:Poisson}

Данный процесс встречается в реальной жизни довольно часто;
он описывает поток случайных событий, которые регистрируются с некоторой постоянной <<интенсивностью>>.
Например, речь может идти о регистрации космических частиц, о кликах по ссылке,
о запросах к серверу, о проезжающих по магистрали автомобилях.

Пуассоновский процесс можно неформально определить следующим образом:
пусть ось времени разбита на бесконечно малые промежутки $ \Delta t $.
Тогда пуассоновский процесс ведёт себя следующим образом:
в самом начале он равен нулю,
и на каждом последующем шаге по времени может претерпеть скачок на $ + 1 $ с вероятностью $ \lambda \Delta t $.
Параметр $ \lambda $ называется интенсивностью процесса и характеризует <<скорость>> потока событий.
Дадим формальное определение:

\begin{definition}[Явная конструкция пуассоновского процесса]
    \label{definition:special:Poisson_process_explicit_definition}
    Пусть $ \xi_1, \ldots, \xi_k, \ldots \sim \expdistr(\lambda) $ и независимы в совокупности,
    $ \tau_n = \xi_1 + \ldots + \xi_n $.
    Тогда процесс $ K_t = \sup \{ n \mid \tau_n \leqslant t \} $ называется \defemph{пуассоновским процессом с интенсивностью $ \lambda $}.
\end{definition}

Процесс $ K_t $, построенный
%по случайным величинам $ \xi_k $
способом, указанным выше,
называется \defemph{процессом восстановления, построенным по величинам $ \{ \xi_k \}_{k \in \naturals} $}, и отвечает следующей модели:
в нулевой момент включается прибор, который работает время $ \xi_1 $, после чего ломается.
Одновременно с поломкой включается следующий прибор, который работает случайное время $ \xi_2 $, и так далее.
Величина $ K_t $ отражает количество приборов, введённых в эксплуатацию к моменту $ t $.

\begin{figure}[ht!]
    \centering
    \begin{gnuplot}[terminal=epslatex, terminaloptions={color size 16cm,8cm}]
        set xlabel  "$ t $"
        set xrange  [ 0 : * ] noreverse writeback
        set ylabel  "$ K_t $"
        set yrange  [ 0 : * ] noreverse writeback

        # Grid

        set style line 100 lt 1 lc rgb "#444444" lw 1
        set style line 101 lt 1 lc rgb "#CCCCCC" lw 1
        set style line 102 lt 1 lc rgb "#EEEEEE" lw 1

        set style line 105 lt 1 lc rgb "#444444" lw 3

        set mxtics 5
        set mytics 5
        set grid ytics mytics mxtics xtics ls 100, ls 102

        # Plotting

        set datafile separator ','
        set key autotitle columnhead

        filename = './data/Poisson_realizations.csv'

        stats filename nooutput
        n_cols = STATS_columns > 9 ? 9 : STATS_columns  # В палитре по умолчанию всего 8 цветов.

        plot [0:*] for [i=2:n_cols] filename using 1:i with histeps lw 3 notitle
    \end{gnuplot}
    %\vspace{-32pt}
    \caption{Пример пучка реализаций пуассоновского процесса с интенсивностью $ \lambda = 2 $.}
    \label{figure:special:Poisson_proccess_realizations}
\end{figure}


Приведённая явная конструкция возвращает нас к неформальному определению,
использующему дискретное время с шагом $ \Delta t $.
Можно заметить, что экспоненциальное распределение получается как
предел вероятностного распределения случайной величины~---
времени между соседними скачками~--- при $ \Delta t \to +0 $:
\[
    \proba \{ \xi_i \in [t; t+h) \} = \lim_{\Delta t \to +0} \left( 1 - \lambda \Delta t \right)^{\frac{t}{\Delta t}} \cdot \left( \lambda \Delta t \cdot \frac{h}{\Delta t} + o(h) \right) =
    \lambda e^{-\lambda t} (h + o(h))
\]

Пуассоновский процесс можно определить и иначе.
Для этого введём понятие процесса с независимыми приращениями.

\begin{definition}
    \label{definition:special:independent_deltas}
    Случайный процесс $ X $ называется \defemph{процессом с независимыми приращениями},
    если $ \forall n \in \naturals \;\, \forall \{t_i\}_{i=1}^n \subseteq T $ случайные величины
    $ X_{t_n} - X_{t_{n-1}}, \ldots, X_{t_2} - X_{t_1}, X_{t_1} $
    независимы в совокупности.
\end{definition}

\begin{definition}
    \label{definition:special:Poisson_process}
    \defemph{Пуассоновским процессом с интенсивностью $ \lambda > 0 $} называется случайный процесс $ K\colon \Omega \times [0; +\infty) \to \naturals $ такой, что
    \begin{enumerate}
        \item
            $ K_0 \almosteq 0 $.
        \item
            $ K $~--- процесс с независимыми приращениями.
        \item
            $ K_t - K_s \sim \poisson\left( \lambda \cdot (t - s) \right) $ (при $ t > s \geqslant 0 $).
    \end{enumerate}
\end{definition}

\begin{theorem}
    \label{theorem:special:Poisson_process_definitions_equivalence}
    Определения \ref{definition:special:Poisson_process_explicit_definition} и \ref{definition:special:Poisson_process} эквивалентны.
\end{theorem}

\begin{statement}
    \label{statement:special:Poisson_process_properties}
    Пуассоновский процесс обладает следующими свойствами:
    \begin{enumerate}
        \item
            Реализации пуассоновского процесса~--- кусочно-постоянные неубывающие функции со значениями в $ \naturals $.
        \item
            С вероятностью $ 1 $ все скачки пуассоновского процесса равны единице.
        \item
            Время, когда произошёл $ n $-ый скачок (обозначим его $ \tau_n $) имеет $ \Gamma(n, 1/\lambda) $-распределение:
            \[
                \rho_{\tau_n}(t) = \frac{\lambda^n x^{n-1}}{(n-1)!} e^{-\lambda t} \cdot \indicator_{[0;+\infty)}(t)
            \]
        \item
            Случайные величины $ \{\tau_{n} - \tau_{n-1}\}_{n \in \naturals} $ распределены экспоненциально с параметром $ \lambda $ и независимы.
        \item
            Число событий за конечный период времени конечно с вероятностью $ 1 $.
        \item
            Число событий $ K_{t+h} - K_t $ на промежутке $ (t; t+h] $ зависит лишь от длины промежутка $ h $:
            $ \proba \{ K_{t + h} - K_t = k \} = p(h, k) $
        \item
            Вероятность более чем одного скачка на полуинтервале $ (t; t + h] $ есть $ o(h) $,
            то есть $ \displaystyle \lim_{h \to +0} \proba \{ K_{t+h} - K_t > 1 \} / h = 0 $.
        \item
            Для коротких полуинтервалов $ (t; t+h] $ вероятность того, что на них произойдёт хотя бы один скачок,
            убывает линейно с уменьшением $ h $: $ \proba \{ K_{t+h} - K_t > 0 \} = 1 - e^{-\lambda h} = \lambda h + o(h) $ при $ h \to 0 $.
        \item
            Из определения распределения Пуассона:
            \[
                \proba\{K_t = k\} = \frac{(\lambda t)^k}{k!} e^{-\lambda t}
            \]
    \end{enumerate}
\end{statement}

Наконец, приведём ещё одно из альтернативных определений пуассоновского процесса:

\begin{statement}
    \label{statement:special:Poisson_process_alternative_definition}
    Случайный процесс $ K\colon \Omega \times T \to \naturals $ является пуассоновским тогда и только тогда, когда он удовлетворяет следующим свойствам:
    \begin{enumerate}
        \item
            \defemph{(стационарность приращений)}
            $ \proba \{ K_{t + h} - K_t = k \} = p(h, k) $
        \item
            \defemph{(отсутствие последействия)}
            Приращения процесса независимы.
        \item
            \defemph{(ординарность)}
            $ \proba \{ K_{t + h} - K_t > 1 \} \in o(h) $
    \end{enumerate}
\end{statement}


\begin{statement}
    \label{statement:special:Poisson_process_correlation_function}
    Пусть $ K $~--- пуассоновский процесс с интенсивностью $ \lambda $.
    Тогда $ m_K(t) = \lambda t $, $ R_K(t, s) = \lambda \cdot \min \{t, s\} $.
\end{statement}

\begin{proof}
    Так как $ K_t \almosteq K_t - K_0 \sim \poisson(\lambda t) $, $ m_K(t) = \expect K_t = \lambda t $.
    Далее, в силу независимости приращений, при $ t \geqslant s $ имеем
    $ \covariance{K_t}{K_s} = \covariance{K_t - K_s + K_s}{K_s} = 0 + \covariance{K_s}{K_s} = \lambda t $.
    Поэтому $ R_k(t, s) = \lambda \cdot \min \{t, s\} $.
\end{proof}


\begin{exercise}
    \label{exercise:special:total_wait_time}
    Поток прибывающих на железнодорожную станцию пассажиров моделируется пуассоновским процессом $ K $ с интенсивностью $ \lambda $.
    В момент $ t = 0 $ пассажиров нет, в момент $ t = t_0 $ прибывает первый поезд.
    Пусть $ \eta $~--- суммарное время ожидания прибытия поезда всеми пассажирами на станции.
    Найти $ \expect \eta $.
\end{exercise}

\begin{solution}
    \[
        \eta = \int\limits_0^{t_0} K_t \, dt, \qquad
        \expect \eta = \int\limits_\Omega d\proba \int\limits_0^{t_0} K_t \, dt = \int\limits_0^{t_0} dt \int\limits_\Omega K_t \, d \proba = \int\limits_0^{t_0} m_K(t) \, dt =
        \int\limits_0^{t_0} \lambda t \, dt = \frac{\lambda t_0^2}{2}
    \]
\end{solution}


\begin{exercise}
    \label{exercise:special:Poisson_process_first_event_conditional}
    Пусть $ K_t $~--- пуассоновский процесс с интенсивностью $ \lambda $,
    а $ \tau_1 $~--- момент первого скачка.
    Найдите $ \proba\{\tau_1 \leqslant s \mid K_t = 1\} $ при $ 0 < s < t $.
\end{exercise}

\begin{solution}
    Событие $ \{ \tau_1 \leqslant s \} $ означает, что первый скачок процесса произошёл не позже момента $ s $.
    Если при этом $ K_t = 1 $, то это означает, что $ K_s = 1 $.
    Тогда
    \begin{multline*}
        \proba \{\tau_1 \leqslant s \mid K_t = 1 \} = \proba \{K_s = 1 \mid K_t = 1\} = \frac{\proba\left( \{K_s = 1\} \cap \{K_t = 1\} \right)}{\proba \{K_t = 1 \}} = \\
        = \frac{\proba\left( \{K_s = 1\} \cap \{K_t - K_s = 0\} \right)}{\proba\{K_t = 1\}}
        = \frac{\frac{\lambda s}{1!} e^{-\lambda s} \cdot \frac{(\lambda(t - s))^0}{0!} e^{-\lambda(t - s)}}{\frac{\lambda t}{1!} e^{-\lambda t}} = \frac{s}{t}
    \end{multline*}
\end{solution}


\begin{exercise}
    \label{exercise:special:Poisson_process_third_event}
    Пусть $ K $~--- пуассоновский процесс с интенсивностью $ \lambda $, $ \tau_3 $~--- время третьего скачка процесса.
    Найти $ \proba \{\tau_3 \leqslant 2 \} $.
\end{exercise}

\begin{solution}
    \noindent
    \[
        \proba \{ \tau_3 \leqslant 2 \} = \proba \{ K_2 \geqslant 3 \} = 1 - \proba \{ K_2 < 3 \} = 1 - e^{-2 \lambda} - \frac{2 \lambda}{1!} e^{-2 \lambda} - \frac{(2 \lambda)^2}{2!} e^{-2 \lambda}
    \]
\end{solution}


\begin{exercise}
    \label{exercise:special:Poisson_process_no_event}
    Пусть $ \eta \sim \uniform_{[0; 1]} $,
    $ K $~--- пуассоновский процесс с интенсивностью $ \lambda $, и $ \eta $ не зависит от $ K $.
    Найти $ \proba\{K_\eta = K_{\eta + 1}\} $.
\end{exercise}

\begin{solution}
    По формуле полной вероятности,
    \[
        \proba \{K_\eta = K_{\eta + 1}\} = \int\limits_\reals \proba\{\underbrace{K_{t + 1} - K_t}_{\sim \poisson(1 \cdot \lambda)} = 0 \mid \eta = t\} \cdot \rho_\eta(t) \, dt =
        \int\limits_0^1 e^{-1 \cdot \lambda} \, dt = e^{-\lambda}
    \]
\end{solution}

Пуассоновский процесс моделирует лишь поток некоторых событий.
Иногда сами события также имеют сложную и/или случайную природу.
Тогда требуется построить более продвинутую модель,
наследующую от пуассоновского процесса только характер возникновения событий с течением времени.
В качестве примера такой модели можно привести \defemph{сложный (составной) пуассоновский процесс}.
Данный процесс может возникнуть, например, при моделировании покупок в магазине:
каждый покупатель будет появляться на кассе согласно пуассоновскому процессу,
при этом закупаясь на некоторое случайное количество денег.

\begin{definition}
    \label{definition:special:compound_Poisson_process}
    Рассмотрим пуассоновский процесс $ K $ и набор независимых (в совокупности с $ K $) одинаково распределённых случайных величин $ \{ V_k \}_{k \in \naturals} $.
    \defemph{Сложным пуассоновским процессом} называется процесс $ \displaystyle Q_t = \sum_{j = 1}^{K_t} V_j $.
\end{definition}

Это означает следующее: $ Q_0 \almosteq 0 $, и в каждый момент, когда $ K $ испытывает скачок, к $ Q $ добавляется $ V_j $.

\begin{statement}
    \label{statement:special:compound_Poisson_process_independent_deltas}
    Сложный пуассоновский процесс является процессом с независимыми приращениями.
\end{statement}

\begin{proof}
    Следует из независимости приращений $ K $ и независимости $ \{V_j\}_{j \in \naturals} $ в совокупности с $ K_t $.
\end{proof}


\begin{statement}
    \label{statement:special:compound_Poisson_process_characteristic_function}
    Рассмотрим сложный пуассоновский процесс $ Q $ с интенсивностью $ \lambda $,
    определённый по случайным величинам $ \{ V_j \}_{j \in \naturals} $.
    Пусть $ \varphi_V(s) $~--- характеристическая функция случайных величин $ V_j $.
    Тогда характеристичекая функция процесса $ Q $ задаётся формулой
    \[
        \varphi_{Q_t}(s) = e^{(\varphi_V(s) - 1) \cdot \lambda t}
    \]
\end{statement}

\begin{proof}
    \begin{multline*}
        \varphi_{Q_t}(s) = \sum_{k = 0}^\infty \expect \left( e^{i s \cdot Q_t} \mid K_t = k \right) \proba \{ K_t = k \} =
        \sum_{k = 0}^\infty \expect \left( e^{i s \cdot (V_1 + \ldots + V_k)} \right) \cdot \frac{(\lambda t)^k}{k!} e^{-\lambda t} = \\
        = \sum_{k = 0}^\infty (\varphi_V(s))^k \cdot \frac{(\lambda t)^k}{k!} e^{-\lambda t} = e^{\varphi_V(s) \cdot \lambda t} \cdot e^{-\lambda t}
    \end{multline*}
\end{proof}


\begin{corollary}
    \label{corollary:special:compound_Poisson_process_moments}
    Функция среднего и корреляционная функция сложного пуассоновского процесса имеют вид, соответственно,
    \[
        m_Q(t) = \lambda t \cdot \expect V, \qquad
        R_Q(t, s) = \lambda \min\{t,s\} \cdot \expect (V^2)
    \]
\end{corollary}

\begin{proof}
    По свойству характеристической функции,
    \begin{multline*}
        m_Q(t) = \expect Q_t = \left . -i \frac{\partial \varphi_{Q_t}(s)}{\partial s} \right|_{s = 0} =
        \left. -i \frac{\partial}{\partial s} \left( e^{(\varphi_V(s) - 1) \cdot \lambda t} \right) \right|_{s = 0} = \\
        = \lambda t \cdot \underbrace{\left( \left. - i \frac{\partial \varphi_V(s)}{\partial s} \right|_{s = 0} \right)}_{\expect V} \cdot
            \underbrace{e^{(\varphi_V(0) - 1) \cdot \lambda t}}_{e^0} =
        \lambda t \cdot \expect V
    \end{multline*}
    Пользуясь независимостью приращений и полагая $ t \leqslant s $,
    \[
        R_Q(t,s) = \expect Q_t Q_s - m_Q(t) m_Q(s) = \expect \left( Q_t (Q_s - Q_t) \right) + \expect Q_t^2 - \lambda^2 t s \cdot (\expect V)^2
    \]
    \[
        \expect \left( Q_t (Q_s - Q_t) \right) = \expect Q_t \cdot \expect (Q_s - Q_t) = \lambda t \cdot \expect V \cdot \lambda (s - t) \cdot \expect V = \lambda^2 t (s - t) \cdot (\expect V)^2
    \]
    \[
        \expect (Q_t)^2 = \left. (- i)^2 \frac{\partial^2}{\partial s^2} \left( e^{(\varphi_V(s) - 1) \cdot \lambda t} \right) \right|_{s = 0} = (\lambda t)^2 (\expect V)^2 + \lambda t \cdot \expect (V^2)
    \]
    Собирая всё вместе, получаем
    \[
        R_Q(t,s) = \lambda^2 [ \underbrace{t(s - t) + t^2 - ts}_{0} ] \cdot (\expect V)^2 + \lambda t \cdot \expect (V^2) = \lambda t \cdot \expect (V^2)
    \]
    В общем же случае $ R_Q(t, s) = \lambda \min\{t,s\} \cdot \expect (V^2) $.
\end{proof}

\begin{exercise}[subtitle={(Прореживание пуассоновского процесса)}]
    \label{exercise:special:Poisson_process_decimation}
    Пусть $ K_t $~--- пуассоновский процесс с интенсивностью $ \lambda $,
    а случайные величины $ \{V_j\}_{j \in \naturals} $ независимы и имеют распределение Бернулли с параметром $ p $.
    Покажите, что $ Q_t $~--- также пуассоновский процесс с интенсивностью $ p \lambda $.
\end{exercise}

\begin{solution}
    Пуассоновский процесс также является сложным пуассоновским процессом с $ V_j \equiv 1 $.
    Тогда характеристическая функция пуассоновского процесса:
    \[
        \varphi_{K_t}(s) = e^{\left(e^{i s} - 1 \right) \cdot \lambda t}
    \]
    Характеристическая функция <<прореженного>> процесса $ Q $:
    \[
        \varphi_{Q_t}(s) = e^{\left(p \, e^{i s} + (1 - p) - 1 \right) \cdot \lambda t} = e^{\left(e^{i s} - 1 \right) \cdot p \lambda t}
    \]
    Имеем характеристическую функцию пуассоновского процесса с интенсивностью $ p \lambda $.
    В общем случае этого недостаточно для того, чтобы утверждать, что процесс пуассоновский;
    нужно равенство характеристических функций всех конечномерных распределений.
    Но мы имеем дело с процессом с независимыми и стационарными приращениями,
    поэтому характеристической функции сечения нам достаточно
    (это утверждение мы оставим без доказательства).
\end{solution}




\subsection{Гауссовские процессы} \label{subsection:special:gaussian}

Гауссовские процессы могут возникать при исследовании броуновского движения,
динамики цен акций, эволюции квантово-механических систем и стохастических космологических моделей.
Также гауссовские процессы часто используется как <<шумовая составляющая>> других случайных процессов.

\begin{definition}
    \label{definition:special:gaussian_process}
    Случайный процесс, все векторы сечений которого являются гауссовскими,
    называется \defemph{гауссовским случайным процессом}.
\end{definition}

Напомним, что гауссовские векторы обладают рядом полезных свойств:
распределение гауссовского вектора полностью задаётся вектором среднего и матрицей ковариации,
а нескоррелированность компонент полностью эквивалентна независимости.
Аналогичные свойства можно доказать и для гауссовских процессов.
Однако для этого требуется ввести следующее определение:

\begin{definition}
    \label{definition:special:positive_semi_definite_function}
    Функция $ g(x, y) \colon X \times X \to \complexes $ называется \defemph{симметричной неотрицательно определённой},
    если $ \forall x, y \in X \;\, g(x, y) = g(y, x) $ и $ \forall n \in \naturals, \; \forall \{x_i\}_{i=1}^n, \{y_j\}_{j=1}^n \subseteq X $
    матрица $ (g(x_i, y_j))_{i,j=1}^n = G_{\{x_i\}, \{y_j\}} $ неотрицательна определена как оператор над $ \complexes^n $,
    то есть $ \forall z \in \complexes^n \; \dotprod{z}{G_{\{x_i\}, \{y_j\}} \, z} \geqslant 0 $.
\end{definition}

\begin{remark}
    \label{remark:special:positive_semi_definite_function_for_reals}
    Если $ g(x, y) $ принимает только вещественные значения,
    в определении \ref{definition:special:positive_semi_definite_function} можно рассматривать только $ z \in \reals^n $.
\end{remark}

\begin{statement}
    \label{statement:special:correlation_function_is_semi_definite}
    Корреляционная функция произвольного случайного процесса является симметричной неотрицательно определённой.
\end{statement}

\begin{statement}
    \label{statement:special:mean_and_cov_define_gaussian_process}
    Пусть $ m \colon T \to \reals $~--- произвольная функция,
    а $ R \colon T \times T \to \reals $~--- симметричная и неотрицательно определённая функция.
    Тогда существует гауссовский процесс $ X $ такой, что $ \expect X_t = m(t) $, $ \expect \rvcenter X_s \rvcenter X_t = R(s, t) $.
\end{statement}

В курсе теории вероятностей вы уже встречались с неотрицательно определёнными функциями.
В частности, все характеристические функции случайных величин неотрицательно определены.

\begin{statement}
    \label{statement:special:characteristic_function_is_positive_semi_definite}
    Пусть $ \varphi_\xi(s) $~--- характеристическая функция некоторой \uline{случайной величины} $ \xi $.
    Тогда функция $ g(s, t) = \varphi_\xi(t - s) $~--- симметричная и неотрицательно определённая.
\end{statement}

\begin{exercise}
    \label{exercise:special:gaussian_from_characteristic_function_of_Cauchy}
    Существует ли гауссовский процесс с корреляционной функцией $ R(s, t) = e^{-|s - t|} $?
\end{exercise}

\begin{solution}
    Да, существует.
    Мы знаем, что $e^{-|t|} $ есть характеристическая функция распределения Коши.
    Поэтому это неотрицательно определённая функция.
    Значит $ R(s, t) = e^{-|s - t|} $ неотрицательно определена и симметрична.
    \newline
    \textit{Пример реализаций процесса
        %из задачи \ref{exercise:special:gaussian_from_characteristic_function_of_Cauchy}
    можно видеть на рис.~\ref{figure:special:gaussian_proccess_te14_realizations}.}
\end{solution}

\begin{figure}[ht!]
    \centering
    \begin{gnuplot}[terminal=epslatex, terminaloptions={color size 16cm,6cm}]
        set xlabel  "$ t $"
        set xrange  [ 0 : * ] noreverse writeback
        set ylabel  "$ X_t $"

        # Grid

        set style line 100 lt 1 lc rgb "#444444" lw 1
        set style line 101 lt 1 lc rgb "#CCCCCC" lw 1
        set style line 102 lt 1 lc rgb "#EEEEEE" lw 1

        set style line 105 lt 1 lc rgb "#444444" lw 3

        set mxtics 5
        set mytics 5
        set grid ytics mytics mxtics xtics ls 100, ls 102

        # Plotting

        set datafile separator ','
        set key autotitle columnhead

        filename = './data/Gaussian_expabs_realizations.csv'

        stats filename nooutput
        n_cols = STATS_columns > 9 ? 9 : STATS_columns  # В палитре по умолчанию всего 8 цветов.

        plot [0:*] for [i=2:n_cols] filename using 1:i with lines lw 3 notitle
    \end{gnuplot}
    %\vspace{-32pt}
    \caption{Пример пучка реализаций гауссовского процесса из задачи \ref{exercise:special:gaussian_from_characteristic_function_of_Cauchy} (среднее взято за ноль).}
    \label{figure:special:gaussian_proccess_te14_realizations}
\end{figure}

Напомним также несколько фактов касательно гауссовских векторов,
которые пригодятся при исследовании гауссовских процессов.

\begin{statement}
    \label{statement:special_gaussian_vetor_affine}
    Пусть $ \xi \sim \normal(\mu, R) $~--- гауссовский вектор размерности $ n \in \naturals $.
    Пусть $ A \in \reals^{m \times n} $, $ b \in \reals^m $~--- произвольные вещественные матрица и вектор.
    Тогда $ (A \xi + b) \sim \normal(A \mu + b, A R A^T) $~--- также гауссовский вектор.
\end{statement}

\FloatBarrier

\begin{theorem}[Формула Вика]
    \label{theorem:special:Wick_formula}
    Пусть дан гауссовский вектор $ (\xi_1, \ldots, \xi_n) \sim \normal(0, R) $
    с корреляционной матрицей $ R = (R_{i,j})_{i,j=1}^n \in \reals^{n \times n} $.
    Тогда
    \begin{enumerate}
        \item
            Если $ n $ нечётно, $ \expect \xi_1 \ldots \xi_n = 0 $.
        \item
            Если $ n $ чётно,
            \[
                \expect \xi_1 \ldots \xi_n = \sum R_{i_1, j_1} \ldots R_{i_n, j_n},
            \]
            где сумма берется по всем неупорядоченным разбиениям множества $ \{1, \ldots, n \} $ на $ n/2 $ неупорядоченных пар.
    \end{enumerate}
\end{theorem}

%\begin{Exercise}[counter=SecExercise, label={
\begin{example}
    \label{example:special:Wick_formula}
    Пусть $ \xi = (\xi_1, \xi_2, \xi_3, \xi_4) \sim \normal(0, R) $.
    Тогда, согласно свойству гауссовского вектора и формуле Вика,
    \[
        \expect \xi_1 \xi_2 \xi_3 = 0, \qquad
        \expect \xi_1 \xi_2 \xi_3 \xi_4 = R_{12} R_{34} + R_{13} R_{24} + R_{14} R_{23}
    \]
\end{example}



\subsubsection{Винеровский процесс} \label{subsubsection:special:Wiener}

Винеровский процесс описывает симметричное случайное блуждание, непрерывное во времени,
и также имеет множество важных приложений.
Данный процесс часто возникает в стохастических дифференциальных уравнениях,
а также при построении других гауссовских процессов.

\begin{figure}[ht!]
    \centering
    \begin{gnuplot}[terminal=epslatex, terminaloptions={color size 16cm,10cm}]
        set xlabel  "$ t $"
        set xrange  [ 0 : * ] noreverse writeback
        set ylabel  "$ W_t $"

        # Grid

        set style line 100 lt 1 lc rgb "#444444" lw 1
        set style line 101 lt 1 lc rgb "#CCCCCC" lw 1
        set style line 102 lt 1 lc rgb "#EEEEEE" lw 1

        set style line 105 lt 1 lc rgb "#444444" lw 3

        set mxtics 5
        set mytics 5
        set grid ytics mytics mxtics xtics ls 100, ls 102

        # Plotting

        set datafile separator ','
        set key autotitle columnhead

        filename = './data/Wiener_realizations.csv'

        stats filename nooutput
        n_cols = STATS_columns > 9 ? 9 : STATS_columns  # В палитре по умолчанию всего 8 цветов.

        plot [0:*] for [i=2:n_cols] filename using 1:i with lines lw 3 notitle
    \end{gnuplot}
    %\vspace{-32pt}
    \caption{Пример пучка реализаций винеровского процесса.}
    \label{figure:special:Wiener_proccess_realizations}
\end{figure}

Неформально винеровский процесс можно определить,
введя мелкую сетку дискретного времени с шагом $ \Delta t $.
Пусть процесс стартует из нуля и на каждом очередном шаге по времени
делает скачок на некоторую случайную величину;
математическое ожидание скачка пусть будет равно нулю, а дисперсия~--- $ \Delta t $
(это сделано для того, чтобы дисперсия сечения процесса была равна прошедшему времени и,
таким образом, не зависела от выбора $ \Delta t $).
Полученные случайные блуждания при $ \Delta t \to +0 $ и описываются винеровским процессом.
Дадим формальное определение.

\begin{definition}
    \label{definition:special:Wiener_process}
    \defemph{Винеровским процессом} называется случайный процесс $ W \colon \Omega \times [0;+\infty) \to \reals $ такой, что
    \begin{enumerate}
        \item $ W_0 \almosteq 0 $.
        \item $ W $~--- процесс с независимыми приращениями.
        \item $ W_t - W_s \sim \normal(0, |t - s|) $.
    \end{enumerate}
\end{definition}

Данное определение напоминает определение пуассоновского процесса;
мы лишь изменили распределение приращений.
Из определения следует, что винеровский процесс~--- гауссовский процесс.
Как было упомянуто ранее, любой гауссовский процесс можно задать его функцией среднего и ковариационной функцией.
Из этого следует второе, эквивалентное определение винеровского процесса:

\begin{definition}
    \label{definition:special:Wiener_process_as_gaussian}
    \defemph{Винеровским процессом} называется гауссовский случайный процесс $ W \colon \Omega \times [0;+\infty) \to \reals $ такой,
    что %$ \expect W_t = 0 $, $ \expect \rvcenter W_t \rvcenter W_s = \min \{t, s\} $.
    $ m_W(t) = 0 $, $ R_W(t, s) = \min \{t, s\} $.
\end{definition}

Наконец, дадим третье эквивалентное определение:

\begin{definition}
    \label{definition:special:Wiener_process_mse}
    \defemph{Винеровским процессом} называется гауссовский случайный процесс $ W \colon \Omega \times [0;+\infty) \to \reals $ такой, что
    \begin{enumerate}
        \item $ W_0 \almosteq 0 $.
        \item $ \expect W_t = 0 $. \label{definition:special:Wiener_process_mse:zero_expectation}
        \item $ \expect (W_t - W_s)^2 = |t - s| $. \label{definition:special:Wiener_process_mse:delta_dispersion}
    \end{enumerate}
\end{definition}


\begin{theorem}
    \label{theorem:special:Wiener_process_definitions_equivalence}
    Определения \ref{definition:special:Wiener_process}, \ref{definition:special:Wiener_process_as_gaussian} и \ref{definition:special:Wiener_process_mse} эквивалентны.
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item[]
        \item[\ref{definition:special:Wiener_process} $ \to $ \ref{definition:special:Wiener_process_as_gaussian}:]
            Из независимости приращений и их нормального распределения следует, что процесс гауссовский
            (любой вектор сечений получается линейным преобразованием из вектора приращений, который является гауссовским).
            Далее, при $ t > s $ имеем $ \expect W_t = \expect (W_t - W_0) = 0 $, $ \covariance{W_t}{W_s} = \covariance{W_s + W_t - W_s}{W_s} = \dispersion W_s = s = \min \{ t, s \} $.
        \item[\ref{definition:special:Wiener_process_as_gaussian} $ \to $ \ref{definition:special:Wiener_process_mse}:]
            $ \expect (W_t - W_s)^2 = \expect W_t^2 - 2 \expect W_t W_s + \expect W_s^2 = t - 2 \min \{ t, s \} + s = |t - s| $.
        \item[\ref{definition:special:Wiener_process_mse} $ \to $ \ref{definition:special:Wiener_process}:]
            Поскольку процесс гауссовский, из пунктов \ref{definition:special:Wiener_process_mse:zero_expectation} и \ref{definition:special:Wiener_process_mse:delta_dispersion}
            определения \ref{definition:special:Wiener_process_mse} следует, что $ W_t - W_s \sim \normal(0, |t - s|) $.
            Прочитав доказательство в предыдущем пункте <<в обратную сторону>>, получаем $ \expect \rvcenter W_t \rvcenter W_s = \min \{t, s\} $.
            Осталось показать независимость приращений.

            Рассмотрим два произвольных последовательных приращения: $ W_{t_4} - W_{t_3} $ и $ W_{t_2} - W_{t_1} $
            ($ t_1 \leqslant t_2 \leqslant t_3 \leqslant t_4 $).
            Они образуют двумерный гауссовский вектор (т.к. получены линейным преобразованием из вектора сечений).
            Приращения нескоррелированны:
            \begin{multline*}
                \covariance{W_{t_4} - W_{t_3}}{W_{t_2} - W_{t_1}} = \min\{t_4, t_2\} - \min\{t_3, t_2\} - \min\{t_4, t_1\} + \min\{t_3, t_1\} = \\
                = t_2 - t_2 - t_1 + t_1 = 0
            \end{multline*}
            Поскольку любой вектор приращений процесса $ W $ гауссовский (см. рассуждение выше про линейное преобразование вектора сечений),
            а его матрица ковариации диагональная (т.к. любые попарные ковариации нулевые),
            из свойств гауссовского вектора получаем независимость.
    \end{enumerate}
\end{proof}

Приведём без доказательства несколько полезных свойств винеровского процесса:

\begin{statement}
    \label{statement:special:Wiener_process_properties}
    \begin{enumerate}
        \item[]
        \item
            Винеровский процесс имеет \defemph{стационарные приращения}
            (конкретно, $ Y_t = W_{t_0 + t} - W_{t_0} $ также винеровский для любого $ t_0 \geqslant 0 $).
        \item
            Винеровский процесс является непрерывным процессом.
        \item
            Траектории винеровского процесса \defemph{возвратны}:
            множество $ \{t \mid W_t = 0\} $ с вероятностью $ 1 $ является неограниченным.
        \item
            Выполнен закон повторного логарифма Леви:
            $ \displaystyle \uplim_{t \to +\infty} \frac{W_t}{\sqrt{2 t \ln \ln t}} \almosteq 1 $.
    \end{enumerate}
\end{statement}

В качестве упражнения приведём доказательства для следующих двух утверждений:

\begin{statement}
    \label{statement:special:Wiener_process_self_similarity}
    Винеровский процесс \defemph{самоподобен с коэффициентом $ 1/2 $},
    то есть $ Y_t = W_{c t} / \sqrt{c} $~--- также винеровский процесс для любой константы $ c > 0 $.
\end{statement}

\begin{proof}
    Процесс $ Y_t $ является гауссовским,
    так как получен из гауссовского процесса линейным (относительно $ W_t $) масштабированием по оси времени и оси значений.
    При этом
    \[
        \expect Y_t = \frac{1}{\sqrt{c}} \cdot 0 = 0, \qquad
        \expect Y_t Y_s = \frac{1}{\sqrt{c} \cdot \sqrt{c}} \min\{ct, cs\} = \min\{t, s\},
    \]
    что по определению означает, что $ Y_t $~--- винеровский.
\end{proof}

\begin{statement}
    \label{statement:special:Wiener_process_time_inverse}
    Винеровский процесс допускает \defemph{<<инверсию времени>>}:
    $ Y_t = t \cdot W_{1/t} $~--- также винеровский процесс.
\end{statement}

\begin{proof}
    Процесс $ Y_t $ является гауссовским,
    так как получен из гауссовского процесса линейным (относительно $ W_t $) масштабированием по оси времени и оси значений.
    При этом
    \[
        \expect Y_t = t \cdot 0 = 0, \qquad
        \expect Y_t Y_s = t s \cdot \min\{1/t, 1/s\} = \min\{t, s\},
    \]
    что по определению означает, что $ Y_t $~--- винеровский.
\end{proof}


\begin{exercise}
    \label{exercise:special:Wiener_process_squared}
    Найдите корреляционную функцию процесса $ X_t = W_t^2 $.
\end{exercise}

\begin{solution}
    Пусть, без ограничения общности, $ t > s $.
    Тогда
    \begin{multline*}
        \covariance{W_t^2}{W_s^2} = \covariance{(W_t - W_s)^2 - 2 W_t W_s - W_s^2}{W_s^2} = \\
        = \covariance{(W_t - W_s)^2 + 2 (W_t - W_s) W_s + W_s^2}{W_s^2} = 0 + \covariance{(W_t - W_s)W_s}{W_s^2} + \dispersion W_s^2
    \end{multline*}
    Поскольку $ W_t - W_s $ и $ W_s $ независимы, $ \expect (W_t - W_s) W_s = 0 $.
    Отсюда
    \[
        \covariance{(W_t - W_s)W_s}{W_s^2} = \expect (W_t - W_s) \underbrace{W_s (W_s^2 - \expect W_s^2)}_{p(W_s)} = \expect (W_t - W_s) \cdot \expect p(W_s) = 0 \cdot \ldots = 0
    \]
    Наконец,
    \[
        \covariance{W_t^2}{W_s^2} = \dispersion W_s^2 = \expect W_s^4 - (\expect W_s^2)^2 \overset{\textnormal{св. норм.}}{\underset{\textnormal{распр.}}{=}} 3 s^2 - s^2 = 2 s^2 = 2 \min\{ t^2, s^2\}
    \]
    Альтернативно, можно было применить формулу Вика:
    \[
        \expect W_t W_t W_s W_s = t \cdot s + \min\{t, s\} \cdot \min\{t, s\} + \min\{t, s\} \cdot \min\{t, s\} = ts + 2 \min\{t^2, s^2\}
    \]
    \[
        \expect W_t^2 = t, \qquad \expect W_s^2 = s
    \]
    \[
        R_{W^2}(t, s) = K_{W^2}(t,s) - m_{W^2}(t) m_{W^2}(s) = ts + 2 \min\{t^2, s^2\} - ts = 2 \min\{t^2, s^2\}
    \]
\end{solution}


\begin{exercise}
    \label{exercise:special:Wiener_process_integral_sum}
    Для винеровского процесса $ W $ и разбиения $ \partition = \{ a = t_0 < t_1 < \ldots < t_{n+1} = b \} $ отрезка $ [a; b] $
    введём случайную величину $ Z(\partition) = \sum_{k=0}^n (W_{t_{k+1}} - W_{t_k} )^2 $.
    Найдите предел в $ \lebesgue_2 $ (в среднем квадратичном) случайных величин $ Z(\partition) $ при устремлении мелкости разбиения $ d(\partition) $ к нулю.
\end{exercise}

\begin{solution}
    Напомним, что случайная величина $ \eta $ является пределом в среднем квадратичном последовательности случайных величин $ \{ \xi_n \}_{n \in \naturals} $,
    если $ \expect |\xi_n - \eta|^2 \limarrow{n \to \infty} 0 $.
    В нашем случае вместо $ n \to \infty $ имеем $ d(\partition) \to 0 $.

    Покажем, что искомым пределом является константная случайная величина~--- $ (b - a) $.
    Для этого заметим, что из независимости приращений и их распределения следует
    \[
        \expect \left( \sum_{k=0}^n (W_{t_{k+1}} - W_{t_k})^2 \right) = \sum_{k=0}^n (t_{k+1} - t_k) = b - a
    \]
    Таким образом, $ (b - a) $ есть ни что иное, как $ \expect Z(\partition) $.
    Тогда
    \[
        \expect \left( \sum_{k=0}^n (W_{t_{k+1}} - W_{t_k})^2 - (b - a) \right)^2 = \dispersion \left( \sum_{k=0}^n (W_{t_{k+1}} - W_{t_k})^2 \right)
    \]
    В очередной раз воспользовавшись независимостью и нормальностью приращений, получаем
    \begin{multline*}
        \dispersion \left( \sum_{k=0}^n (W_{t_{k+1}} - W_{t_k})^2 \right) = \sum_{k=0}^n \dispersion (W_{t_{k+1}} - W_{t_k})^2 = \sum_{k=0}^n \left( 3 (t_{k+1} - t_k)^2 - (t_{k+1} - t_{k})^2 \right) = \\
        = 2 \sum_{k=0}^n (t_{k+1} - t_k)^2 \leqslant 2 \cdot d(\partition) \cdot \sum_{k=0}^n (t_{k+1} - t_k) = 2 \cdot d(\partition) \cdot (b - a) \limarrow{d(\partition) \to 0} 0
    \end{multline*}
\end{solution}


\begin{theorem}[Башелье]
    \label{theorem:special:Bachelier_theorem}
    Пусть $ W $~--- винеровский процесс, $ t > 0 $.
    Случайная величина $ M_t = \sup_{s \in [0; t]} W_s $ имеет такое же распределение, как и $ |W_t| $.
\end{theorem}


\begin{exercise}
    \label{exercise:special:Wiener_process_reach_point_time_expectation}
    Пусть $ W $~--- винеровский процесс, $ y > 0 $ и $ \tau_y = \inf \{ t \mid W_t = y \} $.
    Вычислить $ \expect \tau_y $.
\end{exercise}

\begin{solution}
    Воспользовавшись теоремой \ref{theorem:special:Bachelier_theorem},
    найдём распределение $ \tau_y $:
    \[
        \proba \{ \tau_y \geqslant t \} = \proba \{ M_t < y \} = \proba \{ W_t \in [-y; y] \} = F_{\normal(0, t)}(y) - F_{\normal(0, t)}(-y) = 2 (F_{\normal(0, t)}(y) - 1/2)
    \]
    Заметим, что
    \[
        \frac{\partial}{\partial t} F_{\normal(0, t)}(y) = \frac{\partial}{\partial t} \int\limits_{-\infty}^y \frac{e^{-\frac{x^2}{2 t}}}{\sqrt{2 \pi t}} \, dx =
        \frac{\partial}{\partial t} \int\limits_{-\infty}^{y / \sqrt{t}} \frac{e^{-\frac{x^2}{2}}}{\sqrt{2 \pi}} \, dx = - \frac{y}{2 \sqrt{t^3}} \cdot \frac{e^{-y^2 / 2t}}{\sqrt{2 \pi}}
    \]
    Отсюда
    \[
        \rho_{\tau_y}(t) = \frac{\partial}{\partial t} \proba \{ \tau_y < t \} = \frac{\partial}{\partial t} \left[ 1 - 2 (F_{\normal(0, t)}(y) - 1/2) \right] = \frac{y}{\sqrt{t^3}} \cdot \frac{e^{-y^2 / 2t}}{\sqrt{2 \pi}}
    \]
    \[
        \expect \tau_y = \int\limits_0^{+\infty} t \cdot \rho_{\tau_y}(t) \, dt = + \infty
    \]
\end{solution}


\begin{exercise}
    \label{exercise:special:exponentiated_Wiener_process}
    Пусть $ W $~--- винеровский процесс.
    Вычислить математическое ожидание процесса $ X_t = \exp(W_t - t/2) - 1 $ и доказать,
    что он имеет ортогональные приращения,
    то есть для $ 0 < t_1 < t_2 \leqslant t_3 < t_4 $ справедливо $ \expect \left( (X_{t_4} - X_{t_3})(X_{t_2} - X_{t_1}) \right) = 0 $.
\end{exercise}

\begin{solution}
    Величина $ e^{W_t} $ распределена логнормально с параметрами $ (\mu, \sigma^2) = (0, t) $, а потому $ \expect e^{W_t} = e^{0-t/2} $.
    Тогда $ \expect X_t = e^{t/2 - t/2} - 1 = 0 $.
    Пусть $ 0 < t_1 < t_2 \leqslant t_3 < t_4 $.
    В этом случае
    \begin{multline*}
        \expect \left( \left( e^{W_{t_4} - t_4/2} - e^{W_{t_3} - t_3/2} \right) \left( e^{W_{t_2} - t_2/2} - e^{W_{t_1} - t_1/2} \right) \right) = \\
        = e^{-(t_2 + t_4)/2} \expect \left( e^{W_{t_2} + W_{t_4}} \right) - e^{-(t_1 + t_4)/2} \expect \left( e^{W_{t_1} + W_{t_4}} \right)
        - e^{-(t_2 + t_3)/2} \expect \left( e^{W_{t_2} + W_{t_3}} \right) + e^{-(t_1 + t_3)/2} \expect \left( e^{W_{t_1} + W_{t_3}} \right)
    \end{multline*}
    Рассмотрим произвольное слагаемое (например, первое).
    Пользуясь независимостью приращений,
    \[
        \expect \left( e^{W_{t_2} + W_{t_4}} \right) = \expect \left( e^{2 W_{t_2} + W_{t_4} - W_{t_2}} \right) = \expect \left( e^{2 W_{t_2}} \right) \expect \left( e^{W_{t_4} - W_{t_2}} \right)
    \]
    Аналогично, пользуясь свойством логнормального распределения, получаем
    \[
        \expect \left( e^{2 W_{t_2}} \right) \expect \left( e^{W_{t_4} - W_{t_2}} \right) = e^{4 t_2 / 2} \cdot e^{(t_4 - t_2) / 2}
        \qquad \Longrightarrow \qquad
        e^{-(t_2 + t_4)/2} \expect \left( e^{W_{t_2} + W_{t_4}} \right) = e^{t_2}
    \]
    Отсюда
    \[
        \expect \left( (X_{t_4} - X_{t_3})(X_{t_2} - X_{t_1}) \right) = e^{t_2} - e^{t_1} - e^{t_2} + e^{t_1} = 0
    \]
\end{solution}
